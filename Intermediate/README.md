In order to link a US county to each of the monarch sightings obtained from Journey North, we used a LLM programmatically as suggested in the problem statement. Three python scripts were created to complete this task. 


    ***advanced_year_download.py*** - generates a CSV dataset of all adult monarch sightings from Journey North HTML pages into a master file, distills the master file into a dataset containing US sightings only, and finally creates a dataset containing only the unique city/state combinations from the US sightings dataset.


    ***llm_guess_county_concurrent.py ***- takes the dataset containing unique city/state combinations and executes concurrent requests to GPT-3.5 using the OpenAI API. Utilizes the LLM to, in many cases, successfully retrieve the county a given city is within, despite the data not being valid or properly sanitized in all cases. Creates a new dataset containing the unique city/state combinations from the US dataset, along with the county each city is in.


    ***combine_counties_and_monarch_us.py*** - joins the dataset containing city, state, and county generated by the LLM script with the dataset containing US sightings.


    ***check_correctness_sample.py*** - takes a sample of the final US monarch sighting dataset including generated counties and queries GPT-4, double checking its original output. Displays an estimated error rate within the data concerning town, state, and county matching.

The use of these three scripts allowed us to source all Adult Monarch sightings in the United States from 1997 to the present date that were contained on the Journey North website, and also append the county of the sighting to each row found in the dataset.

**Process:**



1. Execute advanced_year_download.py

    Due to the nature of Journey North and how they chose to make their data available, many queries had to be made to scrape the entire Adult Monarch sighting dataset. The script handles this automatically and generates a complete worldwide sightings dataset across the configured years (monarch_data/monarch_data_all.csv). This is then filtered down into US sightings only (monarch_data/monarch_data_us.csv). Finally, every unique City, State combination is filtered into a new csv containing only the city and state, along with an empty column for county(monarch_data/unique_town_state_us.csv). It must be noted that this data is user submitted and cannot be considered valid or sanitized in all cases. For instance the city “Volente (near Austin)” was submitted by a user instead of “Volente”. We will discuss the estimated error rate within the data later in this section.


    *<span style="text-decoration:underline;">Results:</span>*


    	(monarch_data/monarch_data_all.csv)
		(monarch_data/monarch_data_us.csv)
		(monarch_data/unique_town_state_us.csv)
        $ wc -l monarch_data/*:
		    150855 monarch_data/monarch_data_all.csv
		    137662 monarch_data/monarch_data_us.csv
		    13595 monarch_data/unique_town_state_us.csv



2. Execute llm_guess_county_concurrent.py

    As suggested, append county location onto each of the Monarch sightings contained within the scraped Journey North dataset, we utilized OpenAI’s API. In order to reduce processing time, and more importantly API credit usage, we first distilled the US sightings dataset down into only the unique city and state combinations found within (monarch_data/unique_town_state_us.csv). Finally using the OpenAI API, we query GPT-3.5 with the city and state combination and GPT-3.5 returns its guess at the county. If a county is not able to be found, GPT-3.5 returns ‘NULL’. These queries were executed concurrently to drastically reduce computation time.These results are then compiled into a new dataset (monarch_data/updated_towns_with_counties.csv). Polling the produced dataset, looking for rows where the county is ‘NULL’, we observed a 2.5% rate of failure to retrieve a county. Finally, the script submits a random sample of 200 rows out of 13,500 total rows back into GPT-4, which the LLM estimated to have a 5% error rate, which would include the 2.5% error factor above, plus any rows where GPT-4 rejected its original response to our query. These error rates do not represent the final data however, as we have not yet joined the reduced dataset back to the master US dataset.


    *<span style="text-decoration:underline;">Results:</span>*


        Prompt:
        “Answer only with the name of the county where the city of {town},{state} is located. Add nothing else. If you can't figure it out quickly, respond with NULL. Nothing else."
        
    	(monarch_data/unique_town_state_us.csv) is used to create ->
        (monarch_data/updated_towns_with_counties.csv)

        $ wc -l monarch_data/updated_towns_with_counties.csv
        13595 monarch_data/updated_towns_with_counties.csv

3. Execute combine_counties_and_monarch_us.py

    This script joins (monarch_data/updated_towns_with_counties.csv) on (monarch_data/monarch_data_us.csv) creating (monarch_data/monarch_data_us_with_counties.csv) which is identical to our original master US dataset with the exception of a new column containing the proper county for each row. Polling this entire new dataset with the same techniques as above we observe a 1.38% rate of failure to locate a county for a given row, and feeding a sample of 200 rows from this new dataset back into GPT-4 as before, the LLM now estimates a 1% error rate. The reduction in estimated error rate makes sense as most users conform to proper submission standards, and the unique city state combination dataset (monarch_data/unique_town_state_us.csv) will over represent the users that do not conform to proper submission standards.


*<span style="text-decoration:underline;">Results:</span>*


    	(monarch_data/updated_towns_with_counties.csv) +


    (monarch_data/monarch_data_us.csv) is used to create ->


    (monarch_data/monarch_data_us_with_counties.csv)


    grep ',NULL$' monarch_data/monarch_data_us_with_counties.csv | wc -l


    	1907


    	(1907/137662 = 1.38% miss rate)



4. Execute check_correctness_sample.py

    This script feeds the final combined dataset, containing the Journey North
    data and the GPT generated counties, back into GPT-4 with a simple prompt 
    querying if it thinks the county for a row is correct. An error rate is 
    displayed to the user.

    Results:
        Prompt:
        "In which county is the town of {town} located in {state}? The current 
        data suggests it is in {county}. Is this correct? Answer ONLY 'yes' or 
        'no' NOTHING ELSE."
        (monarch_data/monarch_data_us_with_counties.csv) returns ->
        Error rate: 1.00%